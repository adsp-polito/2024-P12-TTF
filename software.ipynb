{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.constants import WINDOW_SIZE, PRETRAIN_EPOCHS\n",
    "models = [\n",
    "    \"ENCDL\", # The final solution, an encoder regressor with a window size of 19 and a learned positional encoding\n",
    "    \"ENCDS\", # An encoder regressor  with a window size of 19 and a static positional encoding\n",
    "    \"LSTM\", # An LSTM NN\n",
    "    \"RF\", # A Random Forest model\n",
    "    \"LR\", # A linear regressor,\n",
    "    \"ENCDRLfull\", # The final solution but trained on all 4 files\n",
    "]\n",
    "\n",
    "model_paths = {\n",
    "    \"ENCDL\" : f\"saved_models/encdl-{WINDOW_SIZE}-{PRETRAIN_EPOCHS}.model\",\n",
    "    \"ENCDS\" : f\"saved_models/encds-{WINDOW_SIZE}-{PRETRAIN_EPOCHS}.model\",\n",
    "    \"LSTM\" : \"saved_models/lstm.keras\",\n",
    "    \"RF\" : \"saved_models/rforest.model\",\n",
    "    \"LR\" : \"saved_models/lregression.model\",\n",
    "    \"ENCDRLfull\" : f\"saved_models/encd-full.model\",\n",
    "}\n",
    "from src.ml import train_lr, train_rf, predict as predict_ml\n",
    "from src.encoder import train as train_enc, predict as predict_enc\n",
    "from src.lstm import train as train_lstm, predict as predict_lstm\n",
    "\n",
    "\n",
    "model_train_functions = {\n",
    "    \"ENCDL\" : lambda *args: train_enc(*args, True),\n",
    "    \"ENCDS\" : lambda *args: train_enc(*args, False),\n",
    "    \"LSTM\" : train_lstm,\n",
    "    \"RF\" : train_rf,\n",
    "    \"LR\" : train_lr,\n",
    "    \"ENCDRLfull\" : lambda *args: train_enc(*args, True)\n",
    "\n",
    "}\n",
    "\n",
    "model_test_functions = {\n",
    "    \"ENCDL\" : lambda *args: predict_enc(*args, True),\n",
    "    \"ENCDS\" : lambda *args: predict_enc(*args, False),\n",
    "    \"LSTM\" : predict_lstm,\n",
    "    \"RF\" : predict_ml,\n",
    "    \"LR\" : predict_ml,\n",
    "    \"ENCDRLfull\" : lambda *args: predict_enc(*args, True)\n",
    "}\n",
    "\n",
    "model_result_paths =  {\n",
    "    \"ENCDL\" : f\"results_encdl-{WINDOW_SIZE}-{PRETRAIN_EPOCHS}.json\",\n",
    "    \"ENCDS\" : f\"results_encds-{WINDOW_SIZE}-{PRETRAIN_EPOCHS}.json\",\n",
    "    \"LSTM\" : \"results_lstm.json\",\n",
    "    \"RF\" : \"results_rf.json\",\n",
    "    \"LR\" : \"results_lr.json\",\n",
    "    \"ENCDRLfull\" : \"results_full.json\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "/!\\ Chose here the model you want by changing the MODEL variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ENCDRLfull', 19, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL = models[5]\n",
    "PATH = model_paths[MODEL]\n",
    "TRAIN_FUNC = model_train_functions[MODEL]\n",
    "TEST_FUNC = model_test_functions[MODEL]\n",
    "SAVE_PATH = model_result_paths[MODEL]\n",
    "MODEL, WINDOW_SIZE, PRETRAIN_EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x21013c28510>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.preprocessing import scale, denoise, remove_features\n",
    "from src.open_files import TRAIN_FILES\n",
    "\n",
    "from src.preprocessing import windowing\n",
    "from src.open_files import open_train_val\n",
    "from src.constants import TRAIN_FILES, TEST_FILES, RUL_FILES\n",
    "\n",
    "from src.postprocessing import align, aggregate2, aggregate\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import torch\n",
    "torch.random.manual_seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val = open_train_val(TRAIN_FILES[0:1])\n",
    "df_train = scale(denoise(remove_features(df_train)), True)\n",
    "df_val = scale(denoise(remove_features(df_val)))\n",
    "X_train, y_train, _tids_train, _cycles_train = windowing(df_train)\n",
    "X_val, y_val, tids_val, cycles_val = windowing(df_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FUNC(X_train, y_train, X_val, y_val, PATH)\n",
    "y_val_pred = TEST_FUNC(X_val, PATH)\n",
    "df_pred = align(y_val_pred, cycles_val, tids_val)\n",
    "val_ruls, y = aggregate2(df_pred, y_val)\n",
    "print(\"Validation loss:\", np.sqrt(np.mean((val_ruls - y)**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.open_files import open_test\n",
    "df_test = open_test(TEST_FILES[0:1], RUL_FILES[0:1])\n",
    "df_test = scale(denoise(remove_features(df_test)))\n",
    "X_test, y_test, tids_test, cycles_test = windowing(df_test)\n",
    "y_test_pred = TEST_FUNC(X_test, PATH)\n",
    "df_pred = align(y_test_pred, cycles_test, tids_test)\n",
    "test_ruls, y = aggregate(df_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results_fullbywindow2.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(SAVE_PATH, 'w') as f:\n",
    "    json.dump(list(test_ruls), f)\n",
    "\n",
    "with open(f'targets{WINDOW_SIZE}.json', 'w') as f:\n",
    "    json.dump(list(y.astype(float)), f)\n",
    "\n",
    "with open(SAVE_PATH.removesuffix('.json') + f'bywindow2.json', 'w')as f:\n",
    "    print(SAVE_PATH.removesuffix('.json') + f'bywindow2.json')\n",
    "    json.dump(\n",
    "        {'pred' : list(y_test_pred.astype(float)),\n",
    "         'tids' : list(tids_test),\n",
    "         'cycles': list(cycles_test.astype(float)),\n",
    "         'truth' : list(y_test.astype(float))\n",
    "        }, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENCDRLfull\n",
      "Overall Test loss: 424.02858231103204\n",
      "Test loss <20: 195.50857135729765\n",
      "Test loss >20: 448.2804571969074\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(SAVE_PATH, 'r') as f:\n",
    "    test_ruls = np.array(json.load(f))\n",
    "\n",
    "with open(f'targets{WINDOW_SIZE}.json', 'r') as f:\n",
    "    y = np.array(json.load(f))\n",
    "\n",
    "short_rul = y < 20\n",
    "print(MODEL)\n",
    "print(\"Overall Test loss:\", np.sqrt(np.mean((test_ruls - y)**2)))\n",
    "print(\"Test loss <20:\", np.sqrt(np.mean((test_ruls - y)[short_rul]**2)))\n",
    "print(\"Test loss >20:\", np.sqrt(np.mean((test_ruls - y)[~short_rul]**2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
